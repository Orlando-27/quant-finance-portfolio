#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MODULE 51 -- REGIME DETECTION: HMM & MARKOV SWITCHING MODELS
=============================================================================
CQF Concepts Explained: Interactive Jupyter Notebooks
Project 19 of 20 -- Quantitative Finance Portfolio
Author  : Jose Orlando Bobadilla Fuentes | CQF | MSc AI Applied to Fin. Markets
Role    : Senior Quantitative Portfolio Manager & Lead Data Scientist
Firm    : Colombian Pension Fund -- Vicepresidencia de Inversiones

ACADEMIC OVERVIEW
-----------------
Financial markets alternate between distinct statistical regimes â€” bull
markets with high returns and low volatility, bear markets with negative
returns and high volatility, and transitional periods.  Regime detection
models identify these latent states and their transition dynamics.

HIDDEN MARKOV MODEL (HMM)
--------------------------
An HMM assumes that observations y_t are generated by a latent Markov chain
z_t in {1, ..., K} with transition matrix A:

    P(z_t = j | z_{t-1} = i) = A_{ij}

The emission distribution for each state k is Gaussian:
    y_t | z_t = k  ~  N(mu_k, sigma_k^2)

The model parameters theta = {pi, A, mu, sigma} are estimated by the
Baum-Welch algorithm (a special case of EM):

E-step: Compute forward-backward probabilities
    alpha_t(k) = P(y_{1:t}, z_t = k | theta)   [forward variable]
    beta_t(k)  = P(y_{t+1:T} | z_t = k, theta) [backward variable]
    gamma_t(k) = P(z_t = k | y_{1:T}, theta)   [state posterior]
    xi_t(i,j)  = P(z_t=i, z_{t+1}=j | y_{1:T}) [joint posterior]

M-step: Update parameters
    A_ij   = sum_t xi_t(i,j) / sum_t gamma_t(i)
    mu_k   = sum_t gamma_t(k)*y_t / sum_t gamma_t(k)
    sigma_k= sqrt(sum_t gamma_t(k)*(y_t-mu_k)^2 / sum_t gamma_t(k))

VITERBI ALGORITHM
-----------------
The Viterbi algorithm finds the most likely state sequence:
    z*_{1:T} = argmax P(z_{1:T} | y_{1:T}, theta)

Using dynamic programming:
    delta_t(k) = max_{z_{1:t-1}} P(z_{1:t-1}, z_t=k, y_{1:t})
    delta_t(k) = max_j [delta_{t-1}(j) * A_{jk}] * N(y_t; mu_k, sigma_k)

MARKOV SWITCHING AUTOREGRESSION (MS-AR)
-----------------------------------------
Extends HMM to include autoregressive dynamics within each regime:
    y_t = mu_{z_t} + phi_{z_t} * y_{t-1} + sigma_{z_t} * epsilon_t

This captures both level shifts (mu) and momentum changes (phi) across
regimes -- richer than a pure Gaussian HMM.

REGIME-CONDITIONAL STATISTICS
-------------------------------
For each detected regime k, compute:
    mu_k   : mean daily return
    sigma_k: daily volatility
    SR_k   : annualised Sharpe ratio
    Duration: expected time in regime = 1/(1 - A_{kk})

APPLICATIONS
-------------
1. Regime-adaptive asset allocation: reduce equity exposure in bear regime
2. Signal conditioning: trade only in high-IC regime
3. Risk management: increase VaR buffer when switching to high-vol regime
4. Strategy selection: momentum in bull, mean-reversion in bear

REFERENCES
----------
[1] Hamilton, J. (1989). "A New Approach to the Economic Analysis of
    Nonstationary Time Series." Econometrica 57(2):357-384.
[2] Baum, L. et al. (1970). "A Maximization Technique in Statistical
    Estimation." Ann. Math. Stat. 41(1):164-171.
[3] Ang, A. & Bekaert, G. (2002). "International Asset Allocation with
    Regime Shifts." RFS 15(4):1137-1187.
[4] Lopez de Prado, M. (2018). Advances in Financial Machine Learning. Wiley.
=============================================================================
Usage (Cloud Shell):
    cd ~/quant-finance-portfolio/19-cqf-concepts-explained
    python src/m51_regime_detection/m51_regime_detection.py
=============================================================================
"""

import os
import warnings
import numpy as np
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
from scipy.stats import norm
import yfinance as yf

warnings.filterwarnings("ignore")
np.random.seed(42)

# =============================================================================
# PATHS
# =============================================================================
BASE  = os.path.dirname(os.path.abspath(__file__))
ROOT  = os.path.abspath(os.path.join(BASE, "..", ".."))
FIGS  = os.path.join(ROOT, "outputs", "figures", "m51")
os.makedirs(FIGS, exist_ok=True)

# =============================================================================
# DARK THEME
# =============================================================================
DARK   = "#0d1117"
PANEL  = "#161b22"
GRID   = "#21262d"
TEXT   = "#e6edf3"
ACCENT = "#58a6ff"
GREEN  = "#3fb950"
RED    = "#f85149"
AMBER  = "#d29922"
VIOLET = "#bc8cff"
TEAL   = "#39d353"

plt.rcParams.update({
    "figure.facecolor" : DARK,  "axes.facecolor"  : PANEL,
    "axes.edgecolor"   : GRID,  "axes.labelcolor" : TEXT,
    "axes.titlecolor"  : TEXT,  "xtick.color"     : TEXT,
    "ytick.color"      : TEXT,  "text.color"      : TEXT,
    "grid.color"       : GRID,  "grid.linestyle"  : "--",
    "grid.alpha"       : 0.5,   "legend.facecolor": PANEL,
    "legend.edgecolor" : GRID,  "font.family"     : "monospace",
    "font.size"        : 9,     "axes.titlesize"  : 10,
})

def section(n, msg): print(f"  [{n:02d}] {msg}")

# =============================================================================
# HMM IMPLEMENTATION (Baum-Welch + Viterbi, numpy only)
# =============================================================================
class GaussianHMM:
    """
    K-state Gaussian Hidden Markov Model trained via Baum-Welch (EM).

    Parameters
    ----------
    n_states : number of hidden states K
    n_iter   : maximum EM iterations
    tol      : convergence tolerance on log-likelihood

    Attributes (after fit)
    ----------------------
    pi    : (K,)   initial state distribution
    A     : (K,K)  transition matrix
    mu    : (K,)   emission means
    sigma : (K,)   emission standard deviations
    """

    def __init__(self, n_states: int = 2, n_iter: int = 100, tol: float = 1e-4):
        self.K      = n_states
        self.n_iter = n_iter
        self.tol    = tol

    def _emission(self, y: np.ndarray) -> np.ndarray:
        """
        B[t, k] = N(y_t; mu_k, sigma_k)   shape (T, K)
        Numerically stabilised with log-space computation.
        """
        B = np.zeros((len(y), self.K))
        for k in range(self.K):
            B[:, k] = norm.pdf(y, self.mu[k], self.sigma[k] + 1e-9)
        B = np.maximum(B, 1e-300)
        return B

    def _forward(self, B: np.ndarray):
        """
        Scaled forward algorithm.
        alpha_bar[t,k] = P(y_{1:t}, z_t=k) / c_t
        Returns (alpha_bar, log_likelihood)
        """
        T, K  = B.shape
        alpha = np.zeros((T, K))
        scale = np.zeros(T)
        alpha[0] = self.pi * B[0]
        scale[0] = alpha[0].sum() + 1e-300
        alpha[0] /= scale[0]
        for t in range(1, T):
            alpha[t] = (alpha[t-1] @ self.A) * B[t]
            scale[t] = alpha[t].sum() + 1e-300
            alpha[t] /= scale[t]
        log_lik = np.log(scale + 1e-300).sum()
        return alpha, scale, log_lik

    def _backward(self, B: np.ndarray, scale: np.ndarray):
        """Scaled backward algorithm."""
        T, K  = B.shape
        beta  = np.zeros((T, K))
        beta[-1] = 1.0
        for t in range(T-2, -1, -1):
            beta[t] = (self.A * B[t+1]) @ beta[t+1]
            beta[t] /= scale[t+1] + 1e-300
        return beta

    def _e_step(self, y: np.ndarray, B: np.ndarray):
        """Compute gamma and xi posteriors."""
        T = len(y)
        alpha, scale, log_lik = self._forward(B)
        beta  = self._backward(B, scale)
        gamma = alpha * beta
        gamma /= (gamma.sum(axis=1, keepdims=True) + 1e-300)

        xi = np.zeros((T-1, self.K, self.K))
        for t in range(T-1):
            xi[t] = (alpha[t][:, None] * self.A *
                     B[t+1][None, :] * beta[t+1][None, :])
            xi[t] /= xi[t].sum() + 1e-300
        return gamma, xi, log_lik

    def _m_step(self, y: np.ndarray, gamma: np.ndarray, xi: np.ndarray):
        """Update model parameters from sufficient statistics."""
        self.pi    = gamma[0] / (gamma[0].sum() + 1e-300)
        self.A     = xi.sum(axis=0)
        self.A    /= self.A.sum(axis=1, keepdims=True) + 1e-300
        for k in range(self.K):
            g_k          = gamma[:, k]
            self.mu[k]   = (g_k * y).sum() / (g_k.sum() + 1e-300)
            self.sigma[k]= np.sqrt((g_k * (y - self.mu[k])**2).sum() /
                                   (g_k.sum() + 1e-300)) + 1e-6

    def fit(self, y: np.ndarray):
        """
        Baum-Welch EM training.
        Initialises parameters with K-means-style quantile split.
        """
        K = self.K
        # Initialise by quantile split
        pct = np.percentile(y, np.linspace(0, 100, K+1))
        self.mu    = np.array([(pct[k]+pct[k+1])/2 for k in range(K)])
        self.sigma = np.full(K, y.std() / K)
        self.pi    = np.ones(K) / K
        self.A     = np.full((K, K), 1/K)

        log_lik_prev = -np.inf
        self.log_liks = []
        for it in range(self.n_iter):
            B = self._emission(y)
            gamma, xi, log_lik = self._e_step(y, B)
            self._m_step(y, gamma, xi)
            self.log_liks.append(log_lik)
            if abs(log_lik - log_lik_prev) < self.tol:
                break
            log_lik_prev = log_lik

        # Order states by mean (state 0 = lowest mean)
        order     = np.argsort(self.mu)
        self.mu   = self.mu[order]
        self.sigma= self.sigma[order]
        self.pi   = self.pi[order]
        self.A    = self.A[np.ix_(order, order)]
        return self

    def predict_proba(self, y: np.ndarray) -> np.ndarray:
        """Return smoothed state posteriors gamma (T, K)."""
        B = self._emission(y)
        gamma, _, _ = self._e_step(y, B)
        return gamma

    def viterbi(self, y: np.ndarray) -> np.ndarray:
        """
        Viterbi algorithm: most likely state sequence.

        delta_t(k) = max_{z_{1:t-1}} P(z_{1:t-1}, z_t=k, y_{1:t})
        Uses log-space to avoid underflow.
        """
        T  = len(y)
        B  = self._emission(y)
        log_A  = np.log(self.A + 1e-300)
        log_B  = np.log(B + 1e-300)
        delta  = np.zeros((T, self.K))
        psi    = np.zeros((T, self.K), dtype=int)
        delta[0] = np.log(self.pi + 1e-300) + log_B[0]
        for t in range(1, T):
            trans = delta[t-1][:, None] + log_A
            psi[t]   = trans.argmax(axis=0)
            delta[t] = trans.max(axis=0) + log_B[t]
        # Backtrack
        states    = np.zeros(T, dtype=int)
        states[-1]= delta[-1].argmax()
        for t in range(T-2, -1, -1):
            states[t] = psi[t+1, states[t+1]]
        return states

    def regime_stats(self, y: np.ndarray, states: np.ndarray,
                     ann: int = 252) -> list:
        """Per-regime annualised statistics."""
        stats = []
        for k in range(self.K):
            mask = states == k
            if mask.sum() < 5:
                stats.append({})
                continue
            r_k   = y[mask]
            sr    = (r_k.mean() / (r_k.std() + 1e-9)) * np.sqrt(ann)
            dur   = 1.0 / (1 - self.A[k, k] + 1e-9)
            stats.append({
                "mean"    : r_k.mean() * ann,
                "vol"     : r_k.std()  * np.sqrt(ann),
                "sharpe"  : sr,
                "n_days"  : int(mask.sum()),
                "pct"     : mask.mean(),
                "duration": dur,
            })
        return stats


# =============================================================================
# PRINT HEADER + DATA
# =============================================================================
print()
print("=" * 65)
print("  MODULE 51: REGIME DETECTION")
print("  HMM | Baum-Welch | Viterbi | MS-AR | Regime-Adaptive Strategy")
print("=" * 65)

raw   = yf.download("SPY", start="2005-01-01", end="2023-12-31",
                    auto_adjust=True, progress=False)
close = raw["Close"].squeeze().dropna()
ret   = np.log(close / close.shift(1)).dropna().values
dates = close.index[1:]
N     = len(ret)

# Realised vol as second observation signal
rv21  = np.array([ret[max(0,i-21):i].std() for i in range(N)])

section(1, f"SPY returns: {N} days  [{dates[0].date()} -- {dates[-1].date()}]")

# =============================================================================
# 2.  FIT 2-STATE HMM (Bull / Bear)
# =============================================================================
hmm2 = GaussianHMM(n_states=2, n_iter=200, tol=1e-5)
hmm2.fit(ret)
proba2  = hmm2.predict_proba(ret)
states2 = hmm2.viterbi(ret)
stats2  = hmm2.regime_stats(ret, states2)

# Label: state with higher mean = Bull
bull2 = 1; bear2 = 0   # mu[1] > mu[0] by construction (sorted)

section(2, f"2-state HMM fitted  "
           f"Bull: mu={hmm2.mu[bull2]*252:.3f}  sigma={hmm2.sigma[bull2]*np.sqrt(252):.3f}  "
           f"Bear: mu={hmm2.mu[bear2]*252:.3f}  sigma={hmm2.sigma[bear2]*np.sqrt(252):.3f}")
print(f"       Transition A:\n"
      f"         Bull->Bull={hmm2.A[bull2,bull2]:.3f}  Bull->Bear={hmm2.A[bull2,bear2]:.3f}\n"
      f"         Bear->Bull={hmm2.A[bear2,bull2]:.3f}  Bear->Bear={hmm2.A[bear2,bear2]:.3f}")

# =============================================================================
# 3.  FIT 3-STATE HMM (Bull / Neutral / Bear)
# =============================================================================
hmm3 = GaussianHMM(n_states=3, n_iter=200, tol=1e-5)
hmm3.fit(ret)
proba3  = hmm3.predict_proba(ret)
states3 = hmm3.viterbi(ret)
stats3  = hmm3.regime_stats(ret, states3)

STATE_NAMES3 = ["Bear", "Neutral", "Bull"]   # sorted by mu
section(3, f"3-state HMM fitted")
for k in range(3):
    s = stats3[k]
    if s:
        print(f"       {STATE_NAMES3[k]:8s}: mu={s['mean']*100:.1f}%pa  "
              f"vol={s['vol']*100:.1f}%pa  SR={s['sharpe']:.2f}  "
              f"n={s['n_days']}d({s['pct']*100:.0f}%)  "
              f"dur={s['duration']:.0f}d")

# =============================================================================
# 4.  MARKOV SWITCHING AR(1)
# =============================================================================
def fit_ms_ar(y: np.ndarray, states: np.ndarray, K: int = 2) -> dict:
    """
    Fit regime-specific AR(1) models using HMM state assignments.
    y_t = mu_k + phi_k * y_{t-1} + sigma_k * eps_t   for state k

    Returns dict with mu, phi, sigma per state.
    """
    params = {}
    for k in range(K):
        mask = (states[1:] == k)
        if mask.sum() < 10:
            params[k] = {"mu": 0.0, "phi": 0.0, "sigma": y.std()}
            continue
        y_t  = y[1:][mask]
        y_l  = y[:-1][mask]
        X    = np.column_stack([np.ones(len(y_l)), y_l])
        b, _ = np.linalg.lstsq(X, y_t, rcond=None)[:2]
        res  = y_t - X @ b
        params[k] = {"mu": float(b[0]), "phi": float(b[1]),
                     "sigma": float(res.std())}
    return params

ms_ar_params = fit_ms_ar(ret, states2, K=2)
section(4, "MS-AR(1) parameters estimated")
for k in range(2):
    p = ms_ar_params[k]
    lbl = "Bull" if k == bull2 else "Bear"
    print(f"       {lbl}: mu={p['mu']*252:.4f}  phi={p['phi']:.4f}  "
          f"sigma={p['sigma']*np.sqrt(252):.4f}")

# =============================================================================
# 5.  REGIME-ADAPTIVE STRATEGY
# =============================================================================
# Strategy: invest in SPY when P(Bull) > threshold, otherwise hold cash
P_BULL_THRESH = 0.60
p_bull = proba2[:, bull2]
signal_adapt = np.where(p_bull > P_BULL_THRESH, 1.0, 0.0)
ret_adapt = np.zeros(N)
ret_adapt[1:] = signal_adapt[:-1] * ret[1:]    # lag signal

cum_adapt = np.exp(np.cumsum(ret_adapt)) - 1
cum_bnh   = np.exp(np.cumsum(ret))        - 1
sr_adapt  = (ret_adapt.mean() / (ret_adapt.std() + 1e-9)) * np.sqrt(252)
sr_bnh    = (ret.mean()       / (ret.std()        + 1e-9)) * np.sqrt(252)
peak_a    = np.maximum.accumulate(1 + cum_adapt)
mdd_adapt = ((peak_a - (1 + cum_adapt)) / peak_a).max()
peak_b    = np.maximum.accumulate(1 + cum_bnh)
mdd_bnh   = ((peak_b - (1 + cum_bnh))   / peak_b).max()

section(5, f"Regime-adaptive strategy  "
           f"SR={sr_adapt:.3f}  MDD={mdd_adapt:.3f}  "
           f"(BnH SR={sr_bnh:.3f}  MDD={mdd_bnh:.3f})")

# =============================================================================
# 6.  LOG-LIKELIHOOD CONVERGENCE
# =============================================================================
section(6, f"HMM2 converged in {len(hmm2.log_liks)} iterations  "
           f"final LL={hmm2.log_liks[-1]:.2f}")

# =============================================================================
# 7.  REGIME DURATION ANALYSIS
# =============================================================================
def regime_durations(states: np.ndarray, k: int) -> np.ndarray:
    """Extract lengths of consecutive runs in state k."""
    durs = []
    count = 0
    for s in states:
        if s == k:
            count += 1
        else:
            if count > 0:
                durs.append(count)
                count = 0
    if count > 0:
        durs.append(count)
    return np.array(durs) if durs else np.array([0])

bull_durs = regime_durations(states2, bull2)
bear_durs = regime_durations(states2, bear2)

section(7, f"Bull episodes: n={len(bull_durs)}  mean={bull_durs.mean():.0f}d  "
           f"max={bull_durs.max()}d  |  "
           f"Bear episodes: n={len(bear_durs)}  mean={bear_durs.mean():.0f}d  "
           f"max={bear_durs.max()}d")

# =============================================================================
# 8.  REGIME DETECTION ON MULTIPLE ASSETS (cross-sectional)
# =============================================================================
MULTI_TICKERS = ["SPY","TLT","GLD","VIX"]
multi_hmm = {}
for tk in ["SPY","TLT","GLD"]:
    try:
        d  = yf.download(tk, start="2005-01-01", end="2023-12-31",
                         auto_adjust=True, progress=False)
        r_ = np.log(d["Close"].squeeze().dropna() /
                    d["Close"].squeeze().dropna().shift(1)).dropna().values
        h_ = GaussianHMM(n_states=2, n_iter=100, tol=1e-4)
        h_.fit(r_)
        s_ = h_.viterbi(r_)
        multi_hmm[tk] = {"ret": r_, "states": s_, "hmm": h_}
    except Exception:
        pass

section(8, f"Multi-asset regime detection: {list(multi_hmm.keys())}")

# =============================================================================
# FIGURE 1: REGIME OVERVIEW
# =============================================================================
fig = plt.figure(figsize=(16, 14), facecolor=DARK)
fig.suptitle("Module 51 -- HMM Regime Detection: Bull/Bear States",
             fontsize=12, color=TEXT, y=0.99)
gs = gridspec.GridSpec(4, 2, figure=fig, wspace=0.35, hspace=0.45)
t_ = np.arange(N)

# 1A: SPY price + regime shading
ax = fig.add_subplot(gs[0, :])
px = close.values[1:]
ax.plot(t_, px, color=TEXT, lw=0.7, alpha=0.8, label="SPY Price")
bull_mask = states2 == bull2
bear_mask = states2 == bear2
ax.fill_between(t_, px.min()*0.95, px.max()*1.05,
                where=bull_mask, alpha=0.15, color=GREEN, label="Bull regime")
ax.fill_between(t_, px.min()*0.95, px.max()*1.05,
                where=bear_mask, alpha=0.20, color=RED,   label="Bear regime")
ax.set_title("SPY Price with 2-State HMM Regime Classification")
ax.set_xlabel("Day"); ax.set_ylabel("Price (USD)")
ax.legend(fontsize=7, ncol=3); ax.grid(True)

# 1B: P(Bull) posterior probability
ax = fig.add_subplot(gs[1, 0])
ax.plot(t_, p_bull, color=GREEN, lw=0.7, alpha=0.8)
ax.fill_between(t_, p_bull, 0.5, where=p_bull > 0.5, alpha=0.4, color=GREEN)
ax.fill_between(t_, p_bull, 0.5, where=p_bull < 0.5, alpha=0.4, color=RED)
ax.axhline(P_BULL_THRESH, color=AMBER, lw=1.2, ls="--",
           label=f"Threshold={P_BULL_THRESH}")
ax.axhline(0.5, color=GRID, lw=0.8)
ax.set_title("P(Bull) Posterior Probability")
ax.set_xlabel("Day"); ax.set_ylabel("P(Bull state)")
ax.legend(fontsize=7); ax.grid(True)

# 1C: Return distributions by regime
ax = fig.add_subplot(gs[1, 1])
r_bull = ret[bull_mask]
r_bear = ret[bear_mask]
bins_  = np.linspace(ret.min(), ret.max(), 60)
ax.hist(r_bull*100, bins=bins_, alpha=0.6, color=GREEN, density=True,
        label=f"Bull  mu={r_bull.mean()*252*100:.1f}%  sigma={r_bull.std()*np.sqrt(252)*100:.1f}%")
ax.hist(r_bear*100, bins=bins_, alpha=0.6, color=RED,   density=True,
        label=f"Bear  mu={r_bear.mean()*252*100:.1f}%  sigma={r_bear.std()*np.sqrt(252)*100:.1f}%")
ax.set_title("Return Distribution by Regime")
ax.set_xlabel("Daily return (%)"); ax.set_ylabel("Density")
ax.legend(fontsize=7); ax.grid(True)

# 1D: Cumulative returns (strategy vs BnH)
ax = fig.add_subplot(gs[2, 0])
ax.plot(t_, cum_bnh*100,   color=TEXT,  lw=1.2, alpha=0.7,
        label=f"Buy & Hold  SR={sr_bnh:.2f}  MDD={mdd_bnh:.2f}")
ax.plot(t_, cum_adapt*100, color=GREEN, lw=1.5,
        label=f"Regime-adaptive  SR={sr_adapt:.2f}  MDD={mdd_adapt:.2f}")
ax.set_title("Regime-Adaptive Strategy vs Buy & Hold (%)")
ax.set_xlabel("Day"); ax.set_ylabel("Return (%)")
ax.legend(fontsize=7); ax.grid(True)

# 1E: 3-state posterior probabilities stacked
ax = fig.add_subplot(gs[2, 1])
t3 = np.arange(len(proba3))
ax.stackplot(t3, proba3[:, 2], proba3[:, 1], proba3[:, 0],
             labels=["P(Bull)", "P(Neutral)", "P(Bear)"],
             colors=[GREEN, AMBER, RED], alpha=0.8)
ax.set_title("3-State HMM: Stacked Regime Probabilities")
ax.set_xlabel("Day"); ax.set_ylabel("Probability")
ax.legend(fontsize=7, loc="upper left"); ax.grid(False)

# 1F: LL convergence
ax = fig.add_subplot(gs[3, 0])
ax.plot(hmm2.log_liks, color=ACCENT, lw=1.5, label="2-state HMM")
ax.plot(hmm3.log_liks, color=AMBER,  lw=1.5, label="3-state HMM")
ax.set_title("Baum-Welch Log-Likelihood Convergence")
ax.set_xlabel("Iteration"); ax.set_ylabel("Log-likelihood")
ax.legend(fontsize=7); ax.grid(True)

# 1G: Regime duration histograms
ax = fig.add_subplot(gs[3, 1])
ax.hist(bull_durs, bins=30, alpha=0.7, color=GREEN, density=True,
        label=f"Bull  mean={bull_durs.mean():.0f}d")
ax.hist(bear_durs, bins=30, alpha=0.7, color=RED,   density=True,
        label=f"Bear  mean={bear_durs.mean():.0f}d")
ax.set_title("Regime Duration Distribution")
ax.set_xlabel("Duration (days)"); ax.set_ylabel("Density")
ax.legend(fontsize=7); ax.grid(True)

fig.savefig(os.path.join(FIGS, "m51_fig1_regime_overview.png"),
            dpi=150, bbox_inches="tight", facecolor=DARK)
plt.close(fig)

# =============================================================================
# FIGURE 2: TRANSITION MATRIX + MS-AR + MULTI-ASSET
# =============================================================================
fig, axes = plt.subplots(2, 2, figsize=(14, 10), facecolor=DARK)
fig.suptitle("Module 51 -- Transition Matrix, MS-AR & Multi-Asset Regimes",
             fontsize=12, color=TEXT, y=1.01)

# 2A: Transition matrix heatmap
ax = axes[0, 0]
im = ax.imshow(hmm2.A, cmap="YlOrRd", vmin=0, vmax=1, aspect="auto")
labels_2 = ["Bear", "Bull"]
ax.set_xticks([0, 1]); ax.set_xticklabels(["-> Bear", "-> Bull"])
ax.set_yticks([0, 1]); ax.set_yticklabels(["From Bear", "From Bull"])
for i in range(2):
    for j in range(2):
        ax.text(j, i, f"{hmm2.A[i,j]:.3f}",
                ha="center", va="center", fontsize=12,
                color="black" if hmm2.A[i,j] > 0.5 else TEXT, fontweight="bold")
cb = fig.colorbar(im, ax=ax, fraction=0.04, pad=0.03)
cb.set_label("Transition prob", color=TEXT, fontsize=7)
cb.ax.yaxis.set_tick_params(color=TEXT)
ax.set_title("2-State Transition Matrix A")

# 2B: MS-AR regime-conditional return paths
ax = axes[0, 1]
rng_ = np.random.default_rng(0)
for k in range(2):
    p    = ms_ar_params[k]
    path = np.zeros(252)
    for t in range(1, 252):
        path[t] = p["mu"] + p["phi"]*path[t-1] + p["sigma"]*rng_.normal()
    lbl = f"{'Bull' if k==bull2 else 'Bear'}: phi={p['phi']:.3f}"
    col = GREEN if k == bull2 else RED
    for _ in range(5):
        sim = np.zeros(252)
        for t in range(1, 252):
            sim[t] = p["mu"] + p["phi"]*sim[t-1] + p["sigma"]*rng_.normal()
        ax.plot(sim*100, color=col, lw=0.6, alpha=0.4)
    ax.plot(path*100, color=col, lw=1.5, label=lbl)
ax.axhline(0, color=GRID, lw=0.8)
ax.set_title("MS-AR(1): Regime-Conditional Simulated Return Paths")
ax.set_xlabel("Day"); ax.set_ylabel("Daily return (%)"); ax.legend(fontsize=7); ax.grid(True)

# 2C: Multi-asset regime alignment
ax = axes[1, 0]
asset_colors = [ACCENT, AMBER, VIOLET]
for idx, (tk, d) in enumerate(multi_hmm.items()):
    r_tk = d["ret"]
    s_tk = d["states"]
    h_tk = d["hmm"]
    bull_k = np.argmax(h_tk.mu)
    p_bull_tk = d["hmm"].predict_proba(r_tk)[:, bull_k]
    t_tk = np.arange(len(p_bull_tk))
    ax.plot(t_tk, p_bull_tk + idx*1.2, color=asset_colors[idx],
            lw=0.7, alpha=0.8, label=tk)
    ax.axhline(0.5 + idx*1.2, color=GRID, lw=0.4, ls="--")
ax.set_title("Multi-Asset P(Bull) Regimes (offset per asset)")
ax.set_xlabel("Day"); ax.set_ylabel("P(Bull) + offset"); ax.legend(fontsize=7); ax.grid(True)

# 2D: Architecture / theory box
ax = axes[1, 1]
ax.set_facecolor(PANEL); ax.axis("off")
theory = (
    "HMM PARAMETER SUMMARY\n"
    "======================\n\n"
    "2-STATE MODEL:\n"
    f"  Bull: mu={hmm2.mu[bull2]*252*100:.2f}%pa  "
    f"sigma={hmm2.sigma[bull2]*np.sqrt(252)*100:.2f}%pa\n"
    f"  Bear: mu={hmm2.mu[bear2]*252*100:.2f}%pa  "
    f"sigma={hmm2.sigma[bear2]*np.sqrt(252)*100:.2f}%pa\n\n"
    f"  A[Bull,Bull]={hmm2.A[bull2,bull2]:.3f}   "
    f"E[Bull dur]={1/(1-hmm2.A[bull2,bull2]+1e-9):.0f}d\n"
    f"  A[Bear,Bear]={hmm2.A[bear2,bear2]:.3f}   "
    f"E[Bear dur]={1/(1-hmm2.A[bear2,bear2]+1e-9):.0f}d\n\n"
    "3-STATE MODEL:\n"
)
for k, name in enumerate(STATE_NAMES3):
    s = stats3[k]
    if s:
        theory += (f"  {name}: mu={s['mean']*100:.1f}%pa  "
                   f"SR={s['sharpe']:.2f}  "
                   f"n={s['n_days']}d\n")
theory += (
    f"\nREGIME-ADAPTIVE STRATEGY:\n"
    f"  Threshold P(Bull)>{P_BULL_THRESH}\n"
    f"  Sharpe={sr_adapt:.3f}  MDD={mdd_adapt:.3f}\n"
    f"  vs BnH: SR={sr_bnh:.3f}  MDD={mdd_bnh:.3f}\n"
    f"  MDD improvement: {(mdd_bnh-mdd_adapt)*100:.1f}pp"
)
ax.text(0.05, 0.95, theory, transform=ax.transAxes,
        fontsize=8, va="top", fontfamily="monospace",
        color=TEXT, linespacing=1.6)
ax.set_title("Parameter Summary")

for ax in axes.flat:
    ax.set_facecolor(PANEL)

fig.tight_layout()
fig.savefig(os.path.join(FIGS, "m51_fig2_transition_msar_multiasset.png"),
            dpi=150, bbox_inches="tight", facecolor=DARK)
plt.close(fig)

# =============================================================================
# FIGURE 3: EMISSION DISTRIBUTIONS + ROLLING VOL BY REGIME
# =============================================================================
fig, axes = plt.subplots(1, 3, figsize=(16, 5), facecolor=DARK)
fig.suptitle("Module 51 -- Emission Distributions & Rolling Volatility by Regime",
             fontsize=12, color=TEXT, y=1.01)

# 3A: Gaussian emission overlay
ax = axes[0]
xs = np.linspace(ret.min(), ret.max(), 300)
ax.hist(ret*100, bins=80, alpha=0.4, color=TEXT, density=True,
        label="SPY returns", edgecolor="none")
ax.plot(xs*100, norm.pdf(xs, hmm2.mu[bull2], hmm2.sigma[bull2]) *
        stats2[bull2].get("pct", 0.5), color=GREEN, lw=2.0, label="Bull emission")
ax.plot(xs*100, norm.pdf(xs, hmm2.mu[bear2], hmm2.sigma[bear2]) *
        stats2[bear2].get("pct", 0.5), color=RED,   lw=2.0, label="Bear emission")
ax.set_title("Emission Distributions (scaled by P(state))")
ax.set_xlabel("Daily return (%)"); ax.set_ylabel("Density")
ax.legend(fontsize=7); ax.grid(True)

# 3B: Rolling 21d vol coloured by regime
ax = axes[1]
rv21_ = np.array([ret[max(0,i-21):i].std()*np.sqrt(252)*100 for i in range(1, N+1)])
ax.plot(t_, rv21_, color=TEXT, lw=0.5, alpha=0.5)
ax.fill_between(t_, rv21_, 0, where=bull_mask, alpha=0.5, color=GREEN, label="Bull vol")
ax.fill_between(t_, rv21_, 0, where=bear_mask, alpha=0.5, color=RED,   label="Bear vol")
ax.set_title("Rolling 21d Annualised Volatility by Regime (%)")
ax.set_xlabel("Day"); ax.set_ylabel("Vol (%)"); ax.legend(fontsize=7); ax.grid(True)

# 3C: 3-state Viterbi sequence
ax = axes[2]
ax.plot(t_, states3, color=ACCENT, lw=0.5, alpha=0.6)
ax.fill_between(t_, states3, alpha=0.3, color=ACCENT)
ax.set_yticks([0, 1, 2])
ax.set_yticklabels(STATE_NAMES3, fontsize=8)
ax.set_title("3-State Viterbi Path"); ax.set_xlabel("Day"); ax.grid(True)

for ax in axes:
    ax.set_facecolor(PANEL)

fig.tight_layout()
fig.savefig(os.path.join(FIGS, "m51_fig3_emissions_vol_viterbi.png"),
            dpi=150, bbox_inches="tight", facecolor=DARK)
plt.close(fig)

# =============================================================================
# SUMMARY
# =============================================================================
print()
print("  MODULE 51 COMPLETE -- 3 figures saved")
print("  Key Concepts:")
print("  [1] HMM: latent Markov chain z_t drives observable returns y_t")
print("  [2] Baum-Welch (EM): E-step forward-backward, M-step MLE update")
print("  [3] Viterbi: dynamic programming for most likely state sequence")
print("  [4] A[k,k] persistence => E[duration] = 1/(1-A[k,k])")
print(f"  [5] Bull: mu={hmm2.mu[bull2]*252*100:.1f}%pa  "
      f"Bear: mu={hmm2.mu[bear2]*252*100:.1f}%pa  "
      f"(annualised)")
print(f"  [6] Regime-adaptive MDD={mdd_adapt:.3f}  "
      f"vs BnH MDD={mdd_bnh:.3f}  "
      f"improvement={100*(mdd_bnh-mdd_adapt):.1f}pp")
print(f"  [7] Bull duration E[T]={1/(1-hmm2.A[bull2,bull2]+1e-9):.0f}d  "
      f"Bear duration E[T]={1/(1-hmm2.A[bear2,bear2]+1e-9):.0f}d")
print(f"  [8] 3-state model separates crisis, sideways, and trending regimes")
print(f"  NEXT: M52 -- Reinforcement Learning for Trading")
print()
